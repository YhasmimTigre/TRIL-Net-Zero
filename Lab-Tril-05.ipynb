{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab. TRIL - Net Zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engenharia Computacional para a Emissão Zero no Setor de Óleo e Gás"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse é um programa que realiza um processo de leitura, processamento e análise de um conjunto de dados de um reservatório, para encontrar classes de injetividade apresentadas com análise de gráfico.\n",
    "\n",
    "As funcões a serem desenvolvidas são:\n",
    "* read_df (recebe inputs csv ou df)\n",
    "* calc_j (de J para J normalizado)\n",
    "* proc (KDE e Bayesian Blocks)\n",
    "* class (encontrar os pontos e classes)\n",
    "* graf_j (analise dos graficos )\n",
    "\n",
    "Esse projeto é desenvolvido por:<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Preparação de Files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essas funções devem receber arquivos csv (em uma formatação pré-estabelecida) que serem lidos, checados e iniciados.<br>\n",
    "Os arquivos precisam:\n",
    "* ter colunas nomeadas (de preferência em ordem alfabética)\n",
    "* não ter valores NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''função de leitura do arquivo csv para df'''\n",
    "\n",
    "def read_df (arq):\n",
    "    #leitura pelo pandas\n",
    "    df = arq\n",
    "        \n",
    "    #limpeza (valores NAN)\n",
    "    for i in df:\n",
    "       if df[i].isna():\n",
    "           print(\"df com valores NAN\")\n",
    "           df = df[i].fillna(0)\n",
    "    #ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''função de checagem de keys em dataframe '''\n",
    "\n",
    "def checking(df):\n",
    "\n",
    "    #recebe função de leitura\n",
    "    df = read_df(df)\n",
    "\n",
    "    #verificando se falta alguma coluna\n",
    "    lista_base = ['RQI','pressao','pressao_inversa','distancia','permeabilidade','porosidade']\n",
    "        \n",
    "    for i in df.keys(): \n",
    "        if lista_base.count(i) == 0:            \n",
    "            raise KeyError(msg_ERRO = f'variavel {i} não identificada')\n",
    "\n",
    "    return(True,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Calculo dos J's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliza_J (df, *J:list):\n",
    "    \n",
    "    #recebendo função de checagem\n",
    "    df = checking(df)\n",
    "\n",
    "    #atribuição \n",
    "    for j in J:\n",
    "        \n",
    "        if J == 'J1':\n",
    "            J1 = df['RQI']\n",
    "            df['J1'] = J1\n",
    "                    \n",
    "        if J == 'J2':\n",
    "            J2 = df['RQI']*df['pressao']\n",
    "            df['J2'] = J2\n",
    "\n",
    "        if J == 'J3':\n",
    "            J3 = df['RQI']*df['pressao_inversa']\n",
    "            df['J3'] = J3\n",
    "                            \n",
    "        if J == 'J4':\n",
    "            J4 = df['RQI'] * df['pressao'] * np.log(df['distancia']) \n",
    "            df['J4'] = J4\n",
    "\n",
    "        if J == 'J5':\n",
    "            J5 = df['RQI'] * df['pressao_inversa'] * np.log(df['distancia'])\n",
    "            df['J5'] = J5\n",
    "        \n",
    "        if J == 'J6':\n",
    "            J6 = df['permeabilidade'] * df['porosidade'] * np.log(df['distancia'])\n",
    "            df['J6'] = J6\n",
    "        \n",
    "    #normalização\n",
    "    for coluna in df.columns[6:]:\n",
    "        df[f'{coluna}_normalizado'] = (df[coluna] - min(df[coluna])) / (max(df[coluna]) - min(df[coluna]))\n",
    "    \n",
    "    print(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Processamento Binning <br> (Bayesian Blocks ou KDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_binning(df, *J, binning): #recebe o df e o tipo de binning \n",
    "\n",
    "    if binning == 'kde':\n",
    "        \n",
    "        #bibliotecas\n",
    "        from numpy import array, linspace\n",
    "        from sklearn.neighbors import KernelDensity\n",
    "        from scipy.misc import electrocardiogram\n",
    "        from scipy.signal import argrelmin, find_peaks\n",
    "        from sklearn.model_selection import GridSearchCV, LeaveOneOut\n",
    "        import scipy.integrate as integrate\n",
    "\n",
    "        #recebendo J normalizados\n",
    "        df = normaliza_J(df, *J)\n",
    "\n",
    "        #encontrar as curvas com band ideal\n",
    "        #for coluna in J:\n",
    "            #X = df[f'{coluna}_normalizado'].values[::].reshape(-1, 1) #retorna os valores do df com novo formato array\n",
    "            #bandwidths = 10 ** np.linspace(0.01, 0.05) #são as medidas de bandwidth que escolhemos para testar\n",
    "            #grid = GridSearchCV(KernelDensity(), {'bandwidth': bandwidths},cv=LeaveOneOut())\n",
    "            #grid.fit(X1)\n",
    "\n",
    "        min_i = 0\n",
    "        max_i1 = df[f'{coluna}_normalizado'].shape[0]#pega a dimensao da coluna J1\n",
    "        aux1 = max_i1 - min_i\n",
    "\n",
    "\n",
    "        kde_J1= KernelDensity(bandwidth=0.01).fit(X) #por default: gaussian, bandwidth: 1.0\n",
    "        s1 = np.linspace(0, 1.0, aux1) #retorna os pontos em uma distancia equidistante\n",
    "        log1 = kde_J1.score_samples(s1.reshape(-1,1)) #calcula a probabilidade logarítmica de cada amostra sob o modelo\n",
    "                    \n",
    "        #calculo da integral\n",
    "        integrate.trapezoid(np.exp(log1),s1)\n",
    "\n",
    "        #encontrar picos\n",
    "        \n",
    "        #encontrar vales\n",
    "        for coluna in J:\n",
    "            X = sorted(df[f'{coluna}_normalizado'])\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "    elif binning == 'bb':\n",
    "\n",
    "        from astropy.stats import bayesian_blocks\n",
    "\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#teste de integral\n",
    "#calculo da integral sobre o score_samples\n",
    "# import scipy.integrate as integrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle (df, fileout):\n",
    "    import pickle as pkl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficos dos Binnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graf_binning(df, bins, *J, binning): #receberá o df, a quantidade de bins\n",
    "                                         #os J e o tipo de binning\n",
    "    \n",
    "    if binning == 'kde':\n",
    "    elif binning == 'bb':"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Análise dos Gráficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Menu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui vamos chamar o pipeline e apresentar opções ao usuário chamando as funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' TRIL - NetZero '.center(30,'*'))\n",
    "print(' Bem Vindo '.center(30,'*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arq = str(print(\"Insira o caminho para o arquivo: \")) #recebemos o csv\n",
    "\n",
    "arq = pd.read_csv(\"./dados/variaveis.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13584\\1180759507.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#chamando a funçao de preparação\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13584\\1358190000.py\u001b[0m in \u001b[0;36mread_df\u001b[1;34m(arq)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#limpeza (valores NAN)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m        \u001b[1;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m            \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"df com valores NAN\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m            \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Yhasmim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1525\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1527\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1528\u001b[0m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "#chamando a funçao de preparação\n",
    "a = read_df(arq)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### opções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#o df precisa passar pelo calculo dos J's para prosseguir\n",
    "#o usuário deve ter a opção de escolher quais calculos fazer? sim, quais J' normalizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opcao = 0\n",
    "while opcao != 3:\n",
    "    print('''   Qual tipo de processamento voce deseja executar?\n",
    "            digite [1] para Bayesian Blocks\n",
    "            digite [2] para KDE\n",
    "            digite [3] para ambos\n",
    "            digite [4] para voltar ao passo anterior ''')\n",
    "    opcao = int(input())\n",
    "\n",
    "    #if opcao == 1:\n",
    "        # função BB\n",
    "        #print(\"Processo de Binning por Bayesian Block completado\")\n",
    "        #print(imagens dos graficos de bayesian blocks para cada J normalizado)\n",
    "        #o programa pode salvar essas imagens diretamente em um arquivo\n",
    "\n",
    "    #elif opcao == 2:\n",
    "        #função KDE\n",
    "        #print(\"Processo de Binning por KDE completado\")\n",
    "        #print(imagens dos graficos de KDE para cada J normalizado)\n",
    "        #o programa pode salvar essas imagens diretamente em um arquivo\n",
    "\n",
    "    #elif opcao == 3:\n",
    "        # função BB\n",
    "        #função KDE\n",
    "    \n",
    "    #elif opcao == 4:\n",
    "        #break #volta do começo\n",
    "\n",
    "    #else:\n",
    "        #print(\"Esse e um caractere invalido. Deseja recomeçar? Digite [0]\")\n",
    "        #opcao = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Digite se deseja realizar a classificacao: s/n\")\n",
    "resposta = input()\n",
    "\n",
    "#if resposta == 's':\n",
    "    #retornar funcao de classificacao\n",
    "\n",
    "#if resposta == 'n':\n",
    "    #print(\"Fim do Programa\")\n",
    "else: \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandwidth = 0.01"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5e647a0fc3dbcf9eddea2adab39920c93a0982dc82225eeb57e3a95430c0214"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "784ac644c6c4bc21869e2a5fc6787b9327a3f2a01dac292daa186c0832dc0a9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
