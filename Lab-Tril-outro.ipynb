{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab. TRIL - Net Zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engenharia Computacional para a Emissão Zero no Setor de Óleo e Gás"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse é um programa que realiza um processo de leitura, processamento e análise de um conjunto de dados de um reservatório, para encontrar classes de injetividade apresentadas com análise de gráfico.\n",
    "\n",
    "As funcões a serem desenvolvidas são:\n",
    "* read_df (recebe inputs csv ou df)\n",
    "* calc_j (de J para J normalizado)\n",
    "* proc (KDE e Bayesian Blocks)\n",
    "* class (encontrar os pontos e classes)\n",
    "* graf_j (analise dos graficos )\n",
    "\n",
    "Esse projeto é desenvolvido por:<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "#Serve para ignorar os 'red warnings' que algumas bibliotecas apontam porque tem novas versoes de implementacao\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Preparação de Files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essas funções devem receber arquivos csv (em uma formatação pré-estabelecida) que serem lidos, checados e iniciados.<br>\n",
    "Os arquivos precisam:\n",
    "* ter colunas nomeadas (de preferência em ordem alfabética)\n",
    "* não ter valores NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''função de leitura do arquivo csv para df'''\n",
    "\n",
    "def read_df (arq):\n",
    "    #leitura pelo pandas\n",
    "    df = arq\n",
    "    print(df)        \n",
    "    #limpeza (valores NAN)\n",
    "    if any(df.isna()):\n",
    "        print(\"df com valores NAN\")\n",
    "        for i in df:\n",
    "            df = df.fillna(0)\n",
    "        print(\"df corrigido, não mais possui valores NAN\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''função de checagem de keys em dataframe '''\n",
    "\n",
    "def checking(df):\n",
    "\n",
    "    #recebe função de leitura\n",
    "    df = read_df(df)\n",
    "\n",
    "    #verificando se falta alguma coluna\n",
    "    lista_base = ['RQI','pressao','pressao_inversa','distancia','permeabilidade','porosidade']\n",
    "        \n",
    "    for i in df.keys(): \n",
    "        if lista_base.count(i) == 0:            \n",
    "            raise KeyError(msg_ERRO = f'variavel {i} não identificada')\n",
    "\n",
    "    return(True,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Calculo dos J's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliza_J (df, *J:list):\n",
    "    \n",
    "    #recebendo função de checagem\n",
    "    df = checking(df)\n",
    "\n",
    "    #atribuição \n",
    "    for j in J:\n",
    "        \n",
    "        if J == 'J1':\n",
    "            J1 = df['RQI']\n",
    "            df['J1'] = J1\n",
    "                    \n",
    "        if J == 'J2':\n",
    "            J2 = df['RQI']*df['pressao']\n",
    "            df['J2'] = J2\n",
    "\n",
    "        if J == 'J3':\n",
    "            J3 = df['RQI']*df['pressao_inversa']\n",
    "            df['J3'] = J3\n",
    "                            \n",
    "        if J == 'J4':\n",
    "            J4 = df['RQI'] * df['pressao'] * np.log(df['distancia']) \n",
    "            df['J4'] = J4\n",
    "\n",
    "        if J == 'J5':\n",
    "            J5 = df['RQI'] * df['pressao_inversa'] * np.log(df['distancia'])\n",
    "            df['J5'] = J5\n",
    "        \n",
    "        if J == 'J6':\n",
    "            J6 = df['permeabilidade'] * df['porosidade'] * np.log(df['distancia'])\n",
    "            df['J6'] = J6\n",
    "        \n",
    "    #normalização\n",
    "    for coluna in df.columns[6:]:\n",
    "        df[f'{coluna}_normalizado'] = (df[coluna] - min(df[coluna])) / (max(df[coluna]) - min(df[coluna]))\n",
    "    \n",
    "    print(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Processamento Binning <br> (Bayesian Blocks ou KDE)\n",
    "<br/>\n",
    "A classe binning é responsável por processar os dados em KDE ou Bayesian Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class binning():\n",
    "\n",
    "    #método construtor\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def proc_binning(df, *J, binning): #recebe o df e o tipo de binning \n",
    "\n",
    "        if binning == 'kde':\n",
    "            \n",
    "            '''Bibliotecas'''\n",
    "\n",
    "            from numpy import array, linspace\n",
    "            from sklearn.neighbors import KernelDensity\n",
    "            from scipy.misc import electrocardiogram\n",
    "            from scipy.signal import argrelmin, find_peaks\n",
    "            from sklearn.model_selection import GridSearchCV, LeaveOneOut\n",
    "            import scipy.integrate as integrate\n",
    "            \n",
    "            from keras.models import Sequential\n",
    "            from keras.layers import Dense\n",
    "            from keras.layers import Dropout\n",
    "            from keras.wrappers.scikit_learn import KerasClassifier\n",
    "            from keras.constraints import maxnorm\n",
    "            from keras.utils import np_utils\n",
    "            #PARA PICOS\n",
    "            from scipy.misc import electrocardiogram\n",
    "            from scipy.signal import find_peaks\n",
    "            import numpy as np\n",
    "\n",
    "            #recebendo J normalizados\n",
    "            df = normaliza_J(df, *J)\n",
    "\n",
    "            '''Calculo Bandwith''' \n",
    "\n",
    "            #encontrar as curvas com bandwidth ideal com validacao cruzada\n",
    "            for coluna in J:\n",
    "                X = df[f'{coluna}_normalizado'].values[::].reshape(-1, 1)\n",
    "                bandwidth = 10 ** np.linspace(0.01, 0.05) \n",
    "                grid = GridSearchCV(KernelDensity(), {'bandwidth': bandwidth},cv=LeaveOneOut(len(X)))\n",
    "                grid.fit(X) \n",
    "                ideal_band = grid.best_params_\n",
    "            \n",
    "                    \n",
    "            '''Calculo KDE'''   \n",
    "\n",
    "            for coluna in J:\n",
    "                min_i = 0\n",
    "                max_i = df[f'{coluna}_normalizado'].shape[0]#pega a dimensao da coluna \n",
    "                aux = max_i - min_i\n",
    "\n",
    "                kde= KernelDensity(bandwidth = ideal_band).fit(X)\n",
    "                dist = np.linspace(0, 1.0, aux) #retorna os pontos em uma distancia equidistante\n",
    "                log = kde.score_samples(dist.reshape(-1,1)) #calcula a probabilidade logarítmica de cada amostra sob o modelo\n",
    "\n",
    "                '''Calculo das Particoes''' \n",
    "\n",
    "                peaks = find_peaks(log, height=min(log)) # calcula os picos\n",
    "                valleys = argrelmin(log)[0] #Calcula a minima relativa dos dados\n",
    "                \n",
    "                ord = np.argsort(np.abs(np.diff(log[valleys])))#Retorna os indices que classificam o array\n",
    "                ordValleys_J = np.flip(ord)+1\n",
    "\n",
    "\n",
    "            \n",
    "            for coluna in J:\n",
    "\n",
    "                X = sorted(df[f'{coluna}_normalizado'])                           \n",
    "                minimo = min(X)\n",
    "                classes = [minimo]\n",
    "                for i in range(len(peaks)):\n",
    "                    classes.append(X[peaks[i]])                        \n",
    "                classes.append(max(X))\n",
    "\n",
    "            '''Calculo da Integral KDE''' \n",
    "\n",
    "            integral = integrate.trapezoid(np.exp(log),dist)\n",
    "            if 0.99 < integral < 1.01:\n",
    "                print(f'A integral é: {integral}')\n",
    "            else:\n",
    "                print(f'A integral não está no intervalo correto: {integral}')\n",
    "                raise KeyError(msg_ERRO = f'A integral precisa estar entre 0.99 e 1.01')\n",
    "            \n",
    "               \n",
    "\n",
    "        '''Calculo Bayesian Blocks''' \n",
    "\n",
    "        if binning == 'bb':\n",
    "\n",
    "            from astropy.stats import bayesian_blocks\n",
    "            \n",
    "            resultados = {}\n",
    "\n",
    "            for coluna in df.columns:\n",
    "                if coluna in df.columns[12::]:\n",
    "                    serie = df.query(f\"{coluna} > 0\")[coluna]\n",
    "                    resultados[coluna] = [serie, bayesian_blocks(serie)]\n",
    "\n",
    "        '''Imprimindo Informacoes''' \n",
    "\n",
    "        \n",
    "    #return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#teste de integral\n",
    "#calculo da integral sobre o score_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle (df, fileout):\n",
    "    import pickle as pkl\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficos dos Binnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graf_binning(df, bins, *J, binning): #receberá o df, a quantidade de bins\n",
    "                                         #os J e o tipo de binning\n",
    "    \n",
    "    if binning == 'kde':\n",
    "    elif binning == 'bb':"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Análise dos Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class graficos:\n",
    "\n",
    "    def grafico_kde(df, coluna):\n",
    "        \n",
    "\n",
    "\n",
    "    def grafico_bb(df, bins_bb, coluna):\n",
    "        #modificar labels para for\n",
    "        labels = {\n",
    "            \"J1_normalizado\" : \"RQI\",\n",
    "            \"J2_normalizado\" : \"RQI * Pressao\",\n",
    "            \"J3_normalizado\" : \"RQI * Pressao Inversa\",\n",
    "            \"J4_normalizado\" : \"RQI * Pressao * ln(distancia)\",\n",
    "            \"J5_normalizado\" : \"RQI * Pressao Inversa * ln(distancia)\", \n",
    "            \"J6_normalizado\" : \"Permeabilidade * Porosidade * ln(distancia)\",\n",
    "            \"J7_normalizado\" : \"ln(Permeabilidade) * ln(Porosidade) * ln(distancia)\"\n",
    "        }\n",
    "        \n",
    "        ax = plt.figure(figsize=(20, 12))\n",
    "        ax = plt.title(f\"Histograma '{coluna} = {labels[coluna]}' utilizando blocos bayesianos\", fontsize = 24)\n",
    "        ax = plt.xlabel(\"X\", fontsize = 18)\n",
    "        ax = plt.ylabel(\"Y\", fontsize = 18)\n",
    "        ax = plt.hist(df, bins = bins_bb, color='g')\n",
    "        ax = plt.grid(True)\n",
    "        plt.savefig(f'./dados/Analise de Js/{coluna}.jpeg', format='jpeg')\n",
    "        plt.show(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Menu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui vamos chamar o pipeline e apresentar opções ao usuário chamando as funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' TRIL - NetZero '.center(30,'*'))\n",
    "print(' Bem Vindo '.center(30,'*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arq = str(print(\"Insira o caminho para o arquivo: \")) #recebemos o csv\n",
    "\n",
    "arq = pd.read_csv(\"./dados/variaveis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            RQI  pressao_inversa  pressao  porosidade  permeabilidade  \\\n",
      "0      0.112898           4543.9   4608.2    0.062768         0.81143   \n",
      "1      0.085400           4548.2   4604.2    0.050000         0.36985   \n",
      "2      0.088106           4552.9   4600.0    0.050000         0.39366   \n",
      "3      0.086471           4557.9   4595.6    0.050000         0.37919   \n",
      "4      0.088106           4563.0   4590.9    0.050000         0.39366   \n",
      "...         ...              ...      ...         ...             ...   \n",
      "85927  0.064116           4597.3   4560.3    0.112380         0.46856   \n",
      "85928  0.065263           4602.9   4555.2    0.108470         0.46856   \n",
      "85929  0.066356           4608.3   4550.4    0.104920         0.46856   \n",
      "85930  0.039787           4613.5   4545.7    0.107880         0.17321   \n",
      "85931  0.038431           4618.7   4541.1    0.115630         0.17321   \n",
      "\n",
      "       distancia  \n",
      "0            0.0  \n",
      "1            0.0  \n",
      "2            0.0  \n",
      "3            0.0  \n",
      "4            0.0  \n",
      "...          ...  \n",
      "85927        0.0  \n",
      "85928        0.0  \n",
      "85929        0.0  \n",
      "85930        0.0  \n",
      "85931        0.0  \n",
      "\n",
      "[85932 rows x 6 columns]\n",
      "df com valores NAN\n",
      "df corrigido\n"
     ]
    }
   ],
   "source": [
    "#chamando a funçao de preparação\n",
    "a = read_df(arq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RQI\n",
      "pressao_inversa\n",
      "pressao\n",
      "porosidade\n",
      "permeabilidade\n",
      "distancia\n"
     ]
    }
   ],
   "source": [
    "df = arq\n",
    "for i in df:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### opções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#o df precisa passar pelo calculo dos J's para prosseguir\n",
    "#o usuário deve ter a opção de escolher quais calculos fazer? sim, quais J' normalizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opcao = 0\n",
    "while opcao != 3:\n",
    "    print('''   Qual tipo de processamento voce deseja executar?\n",
    "            digite [1] para Bayesian Blocks\n",
    "            digite [2] para KDE\n",
    "            digite [3] para ambos\n",
    "            digite [4] para voltar ao passo anterior ''')\n",
    "    opcao = int(input())\n",
    "\n",
    "    #if opcao == 1:\n",
    "        # função BB\n",
    "        #print(\"Processo de Binning por Bayesian Block completado\")\n",
    "        #print(imagens dos graficos de bayesian blocks para cada J normalizado)\n",
    "        #o programa pode salvar essas imagens diretamente em um arquivo\n",
    "\n",
    "    #elif opcao == 2:\n",
    "        #função KDE\n",
    "        #print(\"Processo de Binning por KDE completado\")\n",
    "        #print(imagens dos graficos de KDE para cada J normalizado)\n",
    "        #o programa pode salvar essas imagens diretamente em um arquivo\n",
    "\n",
    "    #elif opcao == 3:\n",
    "        # função BB\n",
    "        #função KDE\n",
    "    \n",
    "    #elif opcao == 4:\n",
    "        #break #volta do começo\n",
    "\n",
    "    #else:\n",
    "        #print(\"Esse e um caractere invalido. Deseja recomeçar? Digite [0]\")\n",
    "        #opcao = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Digite se deseja realizar a classificacao: s/n\")\n",
    "resposta = input()\n",
    "\n",
    "#if resposta == 's':\n",
    "    #retornar funcao de classificacao\n",
    "\n",
    "#if resposta == 'n':\n",
    "    #print(\"Fim do Programa\")\n",
    "else: \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandwidth = 0.01"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5e647a0fc3dbcf9eddea2adab39920c93a0982dc82225eeb57e3a95430c0214"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "784ac644c6c4bc21869e2a5fc6787b9327a3f2a01dac292daa186c0832dc0a9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
